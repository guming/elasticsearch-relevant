{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Code from Prev Chapters (run first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from elasticsearch import (\n",
    "    Elasticsearch,\n",
    "    helpers\n",
    ")\n",
    "client = Elasticsearch()\n",
    "Headers= {'Content-Type' : \"application/json\" }\n",
    "# Some utilities for flattening the explain into something a bit more\n",
    "# readable. Pass Explain JSON, get something readable (ironically this is what Solr's default output is :-p)\n",
    "def flatten(l):\n",
    "    [item for sublist in l for item in sublist]\n",
    "\n",
    "def simplerExplain(explainJson, depth=0):\n",
    "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explainJson['value'], explainJson['description'])\n",
    "    #print json.dumps(explainJson, indent=True)\n",
    "    if 'details' in explainJson:\n",
    "        for detail in explainJson['details']:\n",
    "            result += simplerExplain(detail, depth=depth+1)\n",
    "    return result\n",
    "\n",
    "\n",
    "# To speed up the pace of development, we really need to focus more heavily on the analysis and query\n",
    "# settings of the search engine, rather than fidly bits of the http interface.\n",
    "#\n",
    "# To that end, we're going to collapse some of the code you were introduced to in chapter 3 into more general functions,\n",
    "# so we can reuse them. Largely, this is the exact same code you saw in chapter 3 some more generality.\n",
    "\n",
    "## Analyze\n",
    "## The analyze function is a helper for accessing the _analyze endpoint like we did in chapter 3. Recall,\n",
    "## given a field or analyzer, passing some text to _analyze will return the token stream that results from\n",
    "## that analyzer. This token stream, if you recall, shows us exactly how the search engine translate text\n",
    "## into individual tokens to be consumed by the underlying data structures. When we debug analysis, we see\n",
    "## matches we need to expect.\n",
    "\n",
    "def analyze(text, field=None, analyzer=None):\n",
    "    whatToAnalyze = ''\n",
    "    if field is not None:\n",
    "        whatToAnalyze = \"field=%s\" % field\n",
    "    elif analyzer is not None:\n",
    "        whatToAnalyze = \"analyzer=%s\" % analyzer\n",
    "    resp = requests.get(\"http://localhost:9200/tmdb/_analyze?%s&format=yaml\" % whatToAnalyze, \n",
    "                        data=text,headers=Headers)\n",
    "    print resp.text\n",
    "    \n",
    "## Search\n",
    "## Next we need to wrap up our execution of query DSL queries. The function 'search' will execute the passed query DSL\n",
    "## query and display the results. \n",
    "## If a scoring explain is associated with the results, then it also gets displayed,\n",
    "## We'll also be sure to dump the query DSL\n",
    "def search(query, verbose=False):\n",
    "    url = 'http://localhost:9200/tmdb/_search'\n",
    "    httpResp = requests.get(url, data=json.dumps(query),headers=Headers)\n",
    "    if httpResp.status_code != 200:\n",
    "        print \"Search Failed <%s>\" % httpResp.status_code\n",
    "        print \"%s\" % httpResp.text\n",
    "    searchHits = json.loads(httpResp.text)['hits']\n",
    "    print \"Num\\tRelevance Score\\t\\tMovie Title\"\n",
    "    for idx, hit in enumerate(searchHits['hits']):\n",
    "            castNames = []            \n",
    "            castCharacters = []                        \n",
    "            directorNames = []\n",
    "            for cast in hit['_source']['cast']:\n",
    "                castNames.append(cast['name'])\n",
    "                castCharacters.append(cast['character'])\n",
    "            for director in hit['_source']['directors']:\n",
    "                directorNames.append(director['name'])\n",
    "            print \"%s\\t%s\\t\\t%s\" % (idx + 1, hit['_score'], hit['_source']['title'])\n",
    "            if verbose:\n",
    "                print \"%s\" % hit['_source']['title']\n",
    "                print \"%s\" % hit['_source']['tagline']        \n",
    "                print \"%s\" % hit['_source']['overview']        \n",
    "                print \"%s\" % hit['_id']\n",
    "                print \"DIRS %s\" % directorNames\n",
    "                print \"CAST %s\" % castNames\n",
    "                print \"CHAR %s\" % castCharacters\n",
    "                if '_explanation' in hit:\n",
    "                    print \"%s\" % simplerExplain(hit['_explanation'])\n",
    "                    print \"*************************************\"\n",
    "    \n",
    "    if verbose:\n",
    "        httpResp = requests.get('http://localhost:9200' + \n",
    "                    '/tmdb/_validate/query?explain',\n",
    "                     data=json.dumps({'query': query['query']}),headers=Headers)\n",
    "        print json.loads(httpResp.text)\n",
    "\n",
    "## Reindex\n",
    "## Reindex takes analyzer and field mappings, recreates the index, and then reindexes\n",
    "## TMDB movies using the _bulk index API. There are other ways for modifying the configuration\n",
    "## of the index besides dropping and restarting, however for convenience and because our data\n",
    "## isn't truly that large, we'll just delete and start from scratch when we need to.\n",
    "def reindex(analysisSettings, mappingSettings=None, movieDict={}):\n",
    "    # Destroy any existing index (equiv to SQL \"drop table\")\n",
    "    resp = requests.delete(\"http://localhost:9200/tmdb\")\n",
    "    print \"Delete TMDB Index <%s>\" % resp.status_code\n",
    "    \n",
    "    # Create the index with explicit settings\n",
    "    # We need to explicitely set number of shards to 1 to eliminate the impact of \n",
    "    # distributed IDF on our small collection\n",
    "    # See also \"Relavance is Broken!\"\n",
    "    # http://www.elastic.co/guide/en/elasticsearch/guide/current/relevance-is-broken.html\n",
    "    settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"index\": {\n",
    "                \"analysis\" : analysisSettings,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if mappingSettings:\n",
    "        settings['mappings'] = mappingSettings\n",
    "    resp = requests.put(\"http://localhost:9200/tmdb\", data=json.dumps(settings),headers=Headers)\n",
    "    print \"Create TMDB Index <%s>\" % resp.status_code\n",
    "    if resp.status_code != 200:\n",
    "        print resp.text\n",
    "    \n",
    "    # Bulk index title & overview to the movie endpoint\n",
    "    print \"Indexing %i movies\" % len(movieDict.keys())\n",
    "    actions = (format_doc(doc) for id,doc in movieDict.iteritems())\n",
    "    results = [details for success,details in helpers.streaming_bulk(client, actions,chunk_size=5000) if not success]\n",
    "\n",
    "    print \"Bulk Index into TMDB Index <%s>\" % results\n",
    "\n",
    "\n",
    "## Extract\n",
    "## major difference between our use of TMDB here and in chapter 3: pulling more data. Not only do we access the \n",
    "## movie endpoint, we also extract the credits -- pulling in the cast (actors and such) and extracting the director.\n",
    "def extract(movieIds=[], numMovies=10000):\n",
    "    if len(movieIds) == 0:\n",
    "        try:\n",
    "            f = open('tmdb.json')\n",
    "            if f:\n",
    "                return json.loads(f.read());\n",
    "        except IOError:\n",
    "            pass       \n",
    "    return movieDict\n",
    "\n",
    "def format_doc(doc):\n",
    "    action = {\n",
    "        \"_index\": \"tmdb\",\n",
    "        \"_type\": \"_doc\",\n",
    "        \"_id\": doc['id'],\n",
    "        \"_source\": doc\n",
    "        }\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index to ES, Chapter 5 Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete TMDB Index <200>\n",
      "Create TMDB Index <200>\n",
      "Indexing 3051 movies\n",
      "Bulk Index into TMDB Index <[]>\n"
     ]
    }
   ],
   "source": [
    "movieDict = extract([])\n",
    "\n",
    "analysisSettings = {\n",
    "   \"analyzer\" : {\n",
    "      \"default\" : {\n",
    "        \"type\" : \"english\"\n",
    "      },\n",
    "      \"english_bigrams\": {\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"porter_stem\",\n",
    "            \"bigram_filter\"\n",
    "          ]\n",
    "      }\n",
    "    },\n",
    "  \"filter\": {\n",
    "    \"bigram_filter\": {\n",
    "        \"type\": \"shingle\",\n",
    "        \"max_shingle_size\":2,\n",
    "        \"min_shingle_size\":2,\n",
    "        \"output_unigrams\":\"false\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "            \n",
    "mappingSettings = {\n",
    "        'properties': {\n",
    "            \"cast\": {\n",
    "               'properties': {\n",
    "                  'name': {\n",
    "                      'type': 'text',\n",
    "                      'analyzer': 'english',\n",
    "                      'fields': {\n",
    "                         \"bigramed\": {\n",
    "                            \"type\": \"text\",\n",
    "                            \"analyzer\": \"english_bigrams\"\n",
    "                        }     \n",
    "                      }\n",
    "                   }\n",
    "                   \n",
    "               }\n",
    "            },\n",
    "            \"directors\": {\n",
    "               'properties': {\n",
    "                  'name': {\n",
    "                      'type': 'text',\n",
    "                      'analyzer': 'english',\n",
    "                      'fields': {\n",
    "                         \"bigramed\": {\n",
    "                            \"type\": \"text\",\n",
    "                            \"analyzer\": \"english_bigrams\"\n",
    "                        }     \n",
    "                      }\n",
    "                   }\n",
    "                   \n",
    "               }\n",
    "            }            \n",
    "        }\n",
    "}\n",
    "\n",
    "reindex(analysisSettings, mappingSettings, movieDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2.2, Listing 3 -- Most Fields undue promotion due to director AND cast member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\t\tMovie Title\n",
      "1\t23.29123\t\tStar Trek: Generations\n",
      "2\t22.615887\t\tStar Trek IV: The Voyage Home\n",
      "3\t20.892147\t\tStar Trek V: The Final Frontier\n",
      "4\t18.406107\t\tStar Trek: Nemesis\n",
      "5\t15.065897\t\tStar Trek: Insurrection\n"
     ]
    }
   ],
   "source": [
    "usersSearch = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': { \n",
    "            'query': usersSearch,  #User's query\n",
    "            'fields': ['title', 'overview', 'cast.name.bigramed', 'directors.name.bigramed'],      \n",
    "            'type': 'most_fields'\n",
    "         }\n",
    "    },\n",
    "    'size': 5,\n",
    "    'explain': True\n",
    "}\n",
    "search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3.2, Listing 7 Query Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\t\tMovie Title\n",
      "1\t14.751948\t\tHannah Montana: The Movie\n",
      "2\t10.895414\t\tStar Trek: Generations\n",
      "3\t10.760254\t\tStar Trek\n",
      "4\t10.057888\t\tStar Trek IV: The Voyage Home\n",
      "5\t9.007851\t\tStar Trek: Nemesis\n"
     ]
    }
   ],
   "source": [
    "usersSearch = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'query_string': { \n",
    "            'query': usersSearch,  #User's query\n",
    "            'fields': ['title', 'overview', 'cast.name.bigramed', 'directors.name.bigramed'],      \n",
    "         }\n",
    "    },\n",
    "    'size': 5,\n",
    "    'explain': True\n",
    "}\n",
    "search(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing 8 -- Searching fields that work in sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\t\tMovie Title\n",
      "1\t14.751948\t\tHannah Montana: The Movie\n",
      "2\t13.600754\t\tStar Trek V: The Final Frontier\n",
      "3\t13.512724\t\tStar Trek: Generations\n",
      "4\t10.760254\t\tStar Trek\n",
      "5\t10.057888\t\tStar Trek IV: The Voyage Home\n"
     ]
    }
   ],
   "source": [
    "usersSearch = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'query_string': { \n",
    "            'query': usersSearch,  #User's query\n",
    "            'fields': ['title', 'overview',\n",
    "  \t\t\t     'cast.name', 'directors.name'],  #A    \n",
    "         }\n",
    "    },\n",
    "    'size': 5,\n",
    "    'explain': True\n",
    "}\n",
    "search(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3.5, Listing 9 -- Tuning Term-Centric Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\t\tMovie Title\n",
      "1\t135.12723\t\tStar Trek: Generations\n",
      "2\t97.44539\t\tShowtime\n",
      "3\t94.6119\t\tOsmosis Jones\n",
      "4\t92.86618\t\tThe Wild\n",
      "5\t86.62215\t\tMiss Congeniality 2: Armed and Fabulous\n"
     ]
    }
   ],
   "source": [
    "usersSearch = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'query_string': { \n",
    "            'query': usersSearch,  #User's query\n",
    "            'fields': ['title', 'overview', \n",
    "   'cast.name^10', 'directors.name'], #A\n",
    "           }\n",
    "    },\n",
    "    'size': 5,\n",
    "    'explain': True\n",
    "}\n",
    "search(query) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4.1, Listings 10&11 Combining Fields into Custom All Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete TMDB Index <200>\n",
      "Create TMDB Index <200>\n",
      "Indexing 3051 movies\n",
      "Bulk Index into TMDB Index <[]>\n"
     ]
    }
   ],
   "source": [
    "mappingSettings = {\n",
    "        'properties': {\n",
    "            # Because of a bug, you have to be very explicit\n",
    "            # about analyzers for cross_field search\n",
    "            \"title\": {\n",
    "              'type': 'text',\n",
    "              'analyzer': 'english',\n",
    "            },\n",
    "            \"overview\": {\n",
    "              'type': 'text',\n",
    "              'analyzer': 'english',\n",
    "            },            \n",
    "            \"people\": {\n",
    "              'properties': {\n",
    "                  'name': {\n",
    "                      'type': 'text',\n",
    "                      'analyzer': 'english',\n",
    "                      'fields': {\n",
    "                         \"bigramed\": {\n",
    "                            \"type\": \"text\",\n",
    "                            \"analyzer\": \"english_bigrams\",\n",
    "                        }     \n",
    "                      }\n",
    "                   }\n",
    "                   \n",
    "               }                       \n",
    "            },\n",
    "            \"cast\": {\n",
    "               'properties': {\n",
    "                  'name': {\n",
    "                      'type': 'text',\n",
    "                      'analyzer': 'english',\n",
    "                      'copy_to': 'people.name',\n",
    "                      'fields': {\n",
    "                         \"bigramed\": {\n",
    "                            \"type\": \"text\",\n",
    "                            \"analyzer\": \"english_bigrams\"\n",
    "                        }     \n",
    "                      }\n",
    "                   }\n",
    "                   \n",
    "               }\n",
    "            },\n",
    "            \"directors\": {\n",
    "               'properties': {\n",
    "                  'name': {\n",
    "                      'type': 'text',\n",
    "                      'analyzer': 'english',\n",
    "                      'copy_to': 'people.name',                      \n",
    "                      'fields': {\n",
    "                         \"bigramed\": {\n",
    "                            \"type\": \"text\",\n",
    "                            \"analyzer\": \"english_bigrams\"\n",
    "                        }     \n",
    "                      }\n",
    "                   }\n",
    "                   \n",
    "               }\n",
    "            }            \n",
    "        }\n",
    "}\n",
    "\n",
    "reindex(analysisSettings, mappingSettings, movieDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4.1, Listing 12 -- Simple use of a custom all field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\t\tMovie Title\n",
      "1\t13.423487\t\tStar Trek: Generations\n",
      "2\t10.511824\t\tStar Trek V: The Final Frontier\n",
      "3\t9.807777\t\tThe Wild\n",
      "4\t9.551281\t\tShowtime\n",
      "5\t9.049201\t\tOsmosis Jones\n"
     ]
    }
   ],
   "source": [
    "usersSearch = 'patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'match': { \n",
    "            'people.name': usersSearch,  #User's query\n",
    "         }\n",
    "    },\n",
    "    'size': 5,\n",
    "    'explain': True\n",
    "}\n",
    "search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing 13 -- Searching _all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\t\tMovie Title\n"
     ]
    }
   ],
   "source": [
    "usersSearch = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'match': { \n",
    "            '_all': usersSearch,  #User's query\n",
    "         }\n",
    "    },\n",
    "    'size': 5,\n",
    "    'explain': True\n",
    "}\n",
    "search(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4.2, Listing 14 -- Cross Field Search over useful fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\t\tMovie Title\n",
      "1\t21.658974\t\tStar Trek: Generations\n",
      "2\t15.192904\t\tStar Trek: Nemesis\n",
      "3\t14.535864\t\tStar Trek: Insurrection\n",
      "4\t14.071022\t\tStar Trek II: The Wrath of Khan\n",
      "5\t13.833348\t\tStar Trek: The Motion Picture\n",
      "6\t13.661812\t\tStar Trek V: The Final Frontier\n",
      "7\t13.471859\t\tStar Trek IV: The Voyage Home\n",
      "8\t13.214497\t\tStar Trek: First Contact\n",
      "9\t13.203346\t\tStar Trek III: The Search for Spock\n",
      "10\t12.359765\t\tStar Trek VI: The Undiscovered Country\n"
     ]
    }
   ],
   "source": [
    "usersSearch = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': { \n",
    "            'query': usersSearch,  #User's query\n",
    "            'fields': ['title', 'overview', 'cast.name', 'directors.name'],\n",
    "            'type': 'cross_fields',\n",
    "         }\n",
    "    },\n",
    "    'size': 10,\n",
    "    'explain': True\n",
    "}\n",
    "search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5.1 -- Listing 15 -- Our Search combining term-centric all field (people.name) w/ other fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\t\tMovie Title\n",
      "1\t25.819304\t\tStar Trek: Generations\n",
      "2\t24.581379\t\tStar Trek IV: The Voyage Home\n",
      "3\t19.045544\t\tStar Trek: Nemesis\n",
      "4\t17.306519\t\tStar Trek V: The Final Frontier\n",
      "5\t16.891613\t\tHannah Montana: The Movie\n"
     ]
    }
   ],
   "source": [
    "usersSearch = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': { \n",
    "            'query': usersSearch,  #User's query\n",
    "            'fields': ['title', 'overview', 'people.name'],\n",
    "            'type': 'most_fields',\n",
    "         }\n",
    "    },\n",
    "    'size': 5,\n",
    "    'explain': True\n",
    "}\n",
    "search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5.2, Listing 16 -- Searching two field groupings â€“ people and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\t\tMovie Title\n",
      "1\t21.525768\t\tStar Trek IV: The Voyage Home\n",
      "2\t19.041664\t\tStar Trek: Generations\n",
      "3\t16.960918\t\tStar Trek: Nemesis\n",
      "4\t14.751948\t\tHannah Montana: The Movie\n",
      "5\t13.620708\t\tStar Trek: Insurrection\n"
     ]
    }
   ],
   "source": [
    "usersSearch = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'bool': {\n",
    "            'should': [ #A\n",
    "                {\n",
    "                   'multi_match': { \n",
    "                      'query': usersSearch,  #User's query\n",
    "                      'fields': ['directors.name.bigramed', #B \n",
    "                                 'cast.name.bigramed'],\n",
    "                      'type': 'cross_fields'\n",
    "                      }\n",
    "                 },\n",
    "                {\n",
    "                   'multi_match': {\n",
    "                     'query': usersSearch,  #User's query\n",
    "                     'fields': ['overview', 'title'],\n",
    "                     'type': 'cross_fields'                                \n",
    "                   }\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'size': 5,\n",
    "    'explain': True\n",
    "}\n",
    "search(query) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5.3 Listing 17 Greedy Term-Centric Paired With Highly Discriminating Like Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num\tRelevance Score\t\tMovie Title\n",
      "1\t32.55439\t\tStar Trek: Generations\n",
      "2\t20.59391\t\tStar Trek: Insurrection\n",
      "3\t20.580244\t\tStar Trek: Nemesis\n",
      "4\t20.264833\t\tStar Trek II: The Wrath of Khan\n",
      "5\t19.561811\t\tStar Trek V: The Final Frontier\n"
     ]
    }
   ],
   "source": [
    "usersSearch = 'star trek patrick stewart william shatner'\n",
    "query = {\n",
    "    'query': {\n",
    "        'bool': {\n",
    "            'should': [ #A\n",
    "                {\n",
    "                   'multi_match': { \n",
    "                      'query': usersSearch,  #User's query\n",
    "                      'fields': ['directors.name.bigramed', #B \n",
    "\t\t\t\t      'cast.name.bigramed'],\n",
    "                      'type': 'cross_fields'\n",
    "                   }\n",
    "                 },\n",
    "                {\n",
    "                   'multi_match': {\n",
    "                     'query': usersSearch,  #User's query\n",
    "                     'fields': ['overview', 'title', #C\n",
    "                                 'directors.name', 'cast.name'],\n",
    "                     'type': 'cross_fields'                                \n",
    "                   }\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'size': 5,\n",
    "    'explain': True\n",
    "}\n",
    "search(query) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
