{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#initialize\n",
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pickle.load(open(\"../movies.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completions from the Documents Being Searched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'acknowledged': True, u'index': u'tmdb', u'shards_acknowledged': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    es.indices.delete(\"tmdb\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#create index here?\n",
    "# genres.name needs to be keyword tokenized so that 'science fiction' doesn't get split on white space\n",
    "# maybe create a text field with title and overview to search against\n",
    "body = {\n",
    "    \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"shingle_2\": {\n",
    "          \"type\":\"shingle\",\n",
    "          \"output_unigrams\":\"false\"}},\n",
    "      \"analyzer\": {\n",
    "        \"completion_analyzer\": {\n",
    "          \"tokenizer\":  \"standard\",\n",
    "          \"filter\": [\n",
    "#             \"standard\", \n",
    "            \"lowercase\", \n",
    "            \"shingle_2\"]}}}},\n",
    "    \"mappings\": {\n",
    "#       \"movie\": {\n",
    "        \"properties\": {\n",
    "          \"genres\": {\n",
    "            \"properties\": {\n",
    "              \"name\": { \n",
    "                \"type\": \"text\",\n",
    "                \"index\": \"false\" }}},\n",
    "          \"title\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"english\",\n",
    "            \"copy_to\":[\"completion\"]},\n",
    "          \"completion\": {\n",
    "            \"type\": \"text\",\n",
    "            \"analyzer\": \"completion_analyzer\"}}}\n",
    "# }\n",
    "}\n",
    "es.indices.create(\"tmdb\",body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc indexer\n",
    "def format_doc(doc):\n",
    "#     print doc\n",
    "    action = {\n",
    "        \"_index\": \"tmdb\",\n",
    "        \"_type\": \"_doc\",\n",
    "        \"_id\": doc['id'],\n",
    "        \"_source\": doc\n",
    "        }\n",
    "    return action\n",
    "\n",
    "def index_movies():\n",
    "    actions = (format_doc(doc) for doc in movies)\n",
    "    results = [details for success,details in helpers.streaming_bulk(es, actions,chunk_size=5000) if not success]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "results = index_movies()\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': ['title'], 'aggregations': {'completion': {'terms': {'field': 'completion', 'include': 'tr.*'}}}, 'query': {'match_phrase_prefix': {'title': {'query': 'star tr'}}}}\n"
     ]
    },
    {
     "ename": "RequestError",
     "evalue": "RequestError(400, u'search_phase_execution_exception', u'Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [completion] in order to load field data by uninverting the inverted index. Note that this can use significant memory.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRequestError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-85ed03f27750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mquery_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_completion_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"star tr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mquery_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tmdb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"_doc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/wanglili/anaconda3/envs/relvant/lib/python2.7/site-packages/elasticsearch/client/utils.pyc\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanglili/anaconda3/envs/relvant/lib/python2.7/site-packages/elasticsearch/client/__init__.pyc\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, index, doc_type, body, params)\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_all'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         return self.transport.perform_request('GET', _make_path(index,\n\u001b[0;32m--> 660\u001b[0;31m             doc_type, '_search'), params=params, body=body)\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     @query_params('_source', '_source_exclude', '_source_include',\n",
      "\u001b[0;32m/Users/wanglili/anaconda3/envs/relvant/lib/python2.7/site-packages/elasticsearch/transport.pyc\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mattempt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTransportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanglili/anaconda3/envs/relvant/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.pyc\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_request_fail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         self.log_request_success(method, full_url, url, body, response.status,\n",
      "\u001b[0;32m/Users/wanglili/anaconda3/envs/relvant/lib/python2.7/site-packages/elasticsearch/connection/base.pyc\u001b[0m in \u001b[0;36m_raise_error\u001b[0;34m(self, status_code, raw_data)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Undecodable raw error response from server: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTP_EXCEPTIONS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRequestError\u001b[0m: RequestError(400, u'search_phase_execution_exception', u'Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [completion] in order to load field data by uninverting the inverted index. Note that this can use significant memory.')"
     ]
    }
   ],
   "source": [
    "def get_completion_query(input_string):\n",
    "    \n",
    "    query_body = {\n",
    "    \"fields\": [\"title\"],\n",
    "    \"query\" : {\n",
    "        \"match_phrase_prefix\" : {\n",
    "            \"title\" : {\n",
    "                \"query\" : input_string}}}}\n",
    "\n",
    "    #if the input string is too short, then don't attempt completion\n",
    "    if len(input_string) < 3:\n",
    "        return query_body\n",
    "    \n",
    "    #get the last uncompleted string\n",
    "    input_string = input_string.lstrip()\n",
    "    last_space_index = input_string.rfind(' ')\n",
    "    prefix = input_string[last_space_index+1:]\n",
    "    \n",
    "    #if the prefix is 1 or less chars then include the previous word in the prefix\n",
    "    if len(prefix) <= 1:\n",
    "        previous_space_index = input_string[:last_space_index].rfind(' ')\n",
    "        prefix = input_string[previous_space_index+1:]\n",
    "        \n",
    "    query_body['aggregations'] = {\n",
    "        'completion': {\n",
    "            'terms': {\n",
    "                'field':'completion',\n",
    "                'include': '%s.*' % prefix\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return query_body\n",
    "    \n",
    "\n",
    "query_body = get_completion_query(\"star tr\")\n",
    "print query_body\n",
    "es.search(index=\"tmdb\",doc_type=\"_doc\",body=query_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Completions Via Specialized Search Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'acknowledged': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    es.indices.delete(\"tmdb\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#create index here?\n",
    "# genres.name needs to be keyword tokenized so that 'science fiction' doesn't get split on white space\n",
    "# maybe create a text field with title and overview to search against\n",
    "body = {\n",
    "    \"mappings\": {\n",
    "      \"movie\": {\n",
    "        \"properties\": {\n",
    "          \"genres\": {\n",
    "            \"properties\": {\n",
    "              \"name\": { \n",
    "                \"type\": \"string\",\n",
    "                \"index\": \"not_analyzed\"}}},\n",
    "          \"title\": {\n",
    "            \"type\": \"string\",\n",
    "            \"analyzer\": \"english\"},\n",
    "          \"completion\": {\n",
    "            \"type\": \"completion\"}}}}}\n",
    "es.indices.create(\"tmdb\",body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc indexer\n",
    "def format_doc(doc):\n",
    "    doc[\"completion\"] = {\n",
    "        \"input\": [doc[\"title\"]],\n",
    "        \"weight\": int(doc[\"popularity\"]*100)\n",
    "    }\n",
    "    action = {\n",
    "        \"_index\": \"tmdb\",\n",
    "        \"_type\": \"movie\",\n",
    "        \"_id\": doc['id'],\n",
    "        \"_source\": doc\n",
    "        }\n",
    "    return action\n",
    "\n",
    "def index_movies():\n",
    "    actions = (format_doc(doc) for doc in movies)\n",
    "    results = [details for success,details in helpers.streaming_bulk(es, actions) if not success]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = index_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_shards': {u'failed': 0, u'successful': 5, u'total': 5},\n",
       " u'title_completion': [{u'length': 4,\n",
       "   u'offset': 0,\n",
       "   u'options': [{u'score': 312.0,\n",
       "     u'text': u'Star Wars: Episode IV - A New Hope'},\n",
       "    {u'score': 298.0, u'text': u'Star Trek Into Darkness'},\n",
       "    {u'score': 280.0, u'text': u'Star Trek'},\n",
       "    {u'score': 221.0, u'text': u'Star Wars: Episode I - The Phantom Menace'},\n",
       "    {u'score': 187.0, u'text': u'Star Wars: Episode VI - Return of the Jedi'}],\n",
       "   u'text': u'star'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_body = { \"title_completion\": {\n",
    "    \"text\": \"star\",\n",
    "    \"completion\": {\n",
    "        \"field\": \"completion\"}}}\n",
    "        \n",
    "es.suggest(index=\"tmdb\",body=suggest_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Search Suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'acknowledged': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    es.indices.delete(\"tmdb\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#create index here?\n",
    "# genres.name needs to be keyword tokenized so that 'science fiction' doesn't get split on white space\n",
    "# maybe create a text field with title and overview to search against\n",
    "body = {\n",
    "    \"mappings\": {\n",
    "      \"movie\": {\n",
    "        \"properties\": {\n",
    "          \"genres\": {\n",
    "            \"properties\": {\n",
    "              \"name\": { \n",
    "                \"type\": \"string\",\n",
    "                \"index\": \"not_analyzed\"}}},\n",
    "          \"title\": {\n",
    "            \"type\": \"string\",\n",
    "            \"analyzer\": \"english\",\n",
    "            \"copy_to\":[\"suggestion\"]},\n",
    "          \"suggestion\": {\n",
    "            \"type\": \"string\"}}}}}\n",
    "es.indices.create(\"tmdb\",body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#doc indexer\n",
    "def format_doc(doc):\n",
    "    action = {\n",
    "        \"_index\": \"tmdb\",\n",
    "        \"_type\": \"movie\",\n",
    "        \"_id\": doc['id'],\n",
    "        \"_source\": doc\n",
    "        }\n",
    "    return action\n",
    "\n",
    "def index_movies():\n",
    "    actions = (format_doc(doc) for doc in movies)\n",
    "    results = [details for success,details in helpers.streaming_bulk(es, actions) if not success]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = index_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_shards': {u'failed': 0, u'successful': 5, u'total': 5},\n",
       " u'title_suggestion': [{u'length': 9,\n",
       "   u'offset': 0,\n",
       "   u'options': [],\n",
       "   u'text': u'star trec'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_body = { \"title_suggestion\": {\n",
    "    \"text\": \"star trec\",\n",
    "    \"phrase\": {\n",
    "        \"field\": \"suggestion\"}}}\n",
    "        \n",
    "es.suggest(index=\"tmdb\",body=suggest_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_shards': {u'failed': 0, u'successful': 5, u'total': 5},\n",
       " u'hits': {u'hits': [{u'_id': u'13475',\n",
       "    u'_index': u'tmdb',\n",
       "    u'_score': 0.83896446,\n",
       "    u'_type': u'movie',\n",
       "    u'fields': {u'title': [u'Star Trek']}},\n",
       "   {u'_id': u'222935',\n",
       "    u'_index': u'tmdb',\n",
       "    u'_score': 0.68552226,\n",
       "    u'_type': u'movie',\n",
       "    u'fields': {u'title': [u'The Fault in Our Stars']}}],\n",
       "  u'max_score': 0.83896446,\n",
       "  u'total': 9},\n",
       " u'suggest': {u'title_completion': [{u'length': 9,\n",
       "    u'offset': 0,\n",
       "    u'options': [{u'score': 0.015584747, u'text': u'star trek'}],\n",
       "    u'text': u'star trec'}]},\n",
       " u'timed_out': False,\n",
       " u'took': 168}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Works in Elasticsearch 1.5\n",
    "query_body = { \n",
    "  \"fields\": [\"title\"],\n",
    "  \"query\": {\n",
    "    \"match\": {\"title\":\"star trec\"}},\n",
    "  \"suggest\": { \"title_completion\": {\n",
    "    \"text\": \"star trec\",\n",
    "    \"phrase\": {\n",
    "      \"field\": \"suggestion\",\n",
    "      \"max_errors\": 2,\n",
    "      \"collate\": {\n",
    "        \"query\": { \n",
    "          \"match_phrase\": {\n",
    "            \"title\" : \"{{suggestion}}\"\n",
    "          }\n",
    "        }}}}}}\n",
    "        \n",
    "es.search(index=\"tmdb\",body=query_body,size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_shards': {u'failed': 0, u'successful': 5, u'total': 5},\n",
       " u'hits': {u'hits': [{u'_id': u'13475',\n",
       "    u'_index': u'tmdb',\n",
       "    u'_score': 0.83896446,\n",
       "    u'_type': u'movie',\n",
       "    u'fields': {u'title': [u'Star Trek']}},\n",
       "   {u'_id': u'222935',\n",
       "    u'_index': u'tmdb',\n",
       "    u'_score': 0.68552226,\n",
       "    u'_type': u'movie',\n",
       "    u'fields': {u'title': [u'The Fault in Our Stars']}}],\n",
       "  u'max_score': 0.83896446,\n",
       "  u'total': 9},\n",
       " u'suggest': {u'title_completion': [{u'length': 9,\n",
       "    u'offset': 0,\n",
       "    u'options': [{u'score': 0.015584747, u'text': u'star trek'}],\n",
       "    u'text': u'star trec'}]},\n",
       " u'timed_out': False,\n",
       " u'took': 35}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Works in Elasticsearch 2.1\n",
    "query_body = { \n",
    "  \"fields\": [\"title\"],\n",
    "  \"query\": {\n",
    "    \"match\": {\"title\":\"star trec\"}},\n",
    "  \"suggest\": { \"title_completion\": {\n",
    "    \"text\": \"star trec\",\n",
    "    \"phrase\": {\n",
    "      \"field\": \"suggestion\",\n",
    "      \"max_errors\": 2,\n",
    "      \"collate\": {\n",
    "        \"query\": { \n",
    "          \"inline\" : {\n",
    "            \"match_phrase\": {\n",
    "              \"title\" : \"{{suggestion}}\"\n",
    "}}}}}}}}\n",
    "\n",
    "es.search(index=\"tmdb\",body=query_body,size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
